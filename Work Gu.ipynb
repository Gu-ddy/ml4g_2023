{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORTANT ! Note that an additional folder ('Models') needs to be created\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.metrics import make_scorer\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# bed and bigwig files contain signals of all chromosomes (including sex chromosomes).\n",
    "# Training and validation split based on chromosomes has been done for you.\n",
    "# However, you can resplit the data in any way you want.\n",
    "\n",
    "# Path for datasets\n",
    "path_cwd = os.getcwd()\n",
    "path_data = path_cwd+\"/ML4G_Project_1_Data\"\n",
    "\n",
    "# Metadata for genes of cell lines X1 and X2\n",
    "train_info_X1_path = path_data+\"/CAGE-train/CAGE-train/X1_train_info.tsv\"\n",
    "train_info_X2_path = path_data+\"/CAGE-train/CAGE-train/X2_train_info.tsv\"\n",
    "val_info_X1_path = path_data+\"/CAGE-train/CAGE-train/X1_val_info.tsv\"\n",
    "val_info_X2_path = path_data+\"/CAGE-train/CAGE-train/X2_val_info.tsv\"\n",
    "\n",
    "# Gene expression values for cell lines X1 and X2\n",
    "train_y_X1_path = path_data+\"/CAGE-train/CAGE-train/X1_train_y.tsv\"\n",
    "train_y_X2_path = path_data+\"/CAGE-train/CAGE-train/X2_train_y.tsv\"\n",
    "val_y_X1_path = path_data+\"/CAGE-train/CAGE-train/X1_val_y.tsv\"\n",
    "val_y_X2_path = path_data+\"/CAGE-train/CAGE-train/X2_val_y.tsv\"\n",
    "\n",
    "# DNase and histone modification data for cell lines X1, X2 and X3\n",
    "bed_files_X1 = [\"/DNase-bed/X1.bed\",\n",
    "                \"/H3K4me1-bed/X1.bed\",\n",
    "                \"/H3K4me3-bed/X1.bed\",\n",
    "                \"/H3K9me3-bed/X1.bed\",\n",
    "                \"/H3K27ac-bed/X1.bed\",\n",
    "                \"/H3K27me3-bed/X1.bed\",\n",
    "                \"/H3K36me3-bed/X1.bed\"]\n",
    "bed_file_paths_X1 = [path_data+file for file in bed_files_X1]\n",
    "\n",
    "bed_files_X2 = [\"/DNase-bed/X2.bed\",\n",
    "                \"/H3K4me1-bed/X2.bed\",\n",
    "                \"/H3K4me3-bed/X2.bed\",\n",
    "                \"/H3K9me3-bed/X2.bed\",\n",
    "                \"/H3K27ac-bed/X2.bed\",\n",
    "                \"/H3K27me3-bed/X2.bed\",\n",
    "                \"/H3K36me3-bed/X2.bed\"]\n",
    "bed_file_paths_X2 = [path_data+file for file in bed_files_X1]\n",
    "\n",
    "bed_files_X3 = [\"/DNase-bed/X3.bed\",\n",
    "                \"/H3K4me1-bed/X3.bed\",\n",
    "                \"/H3K4me3-bed/X3.bed\",\n",
    "                \"/H3K9me3-bed/X3.bed\",\n",
    "                \"/H3K27ac-bed/X3.bed\",\n",
    "                \"/H3K27me3-bed/X3.bed\",\n",
    "                \"/H3K36me3-bed/X3.bed\"]\n",
    "bed_file_paths_X3 = [path_data+file for file in bed_files_X1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "### FUNCTION FOR EXTRACTION OF FEATURES\n",
    "def extract_features(bed_path, info_path, max_distance, resolution, stride,verbose=1):\n",
    "    \"\"\"\n",
    "    Function extracting binary features from bed datasets\n",
    "    :param bed_path: path to bed file of interest\n",
    "    :param info_path: path to info file of interest\n",
    "    :param max_distance: maximal distance from TSS that should be considered\n",
    "    :param resolution: window size of aggregation for dimensionality reduction\n",
    "    :param stride: stride for dimensionality reduction\n",
    "    :param verbose: binary feature for printing progress\n",
    "    :return: pandas df of type int8 containing binary features\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data\n",
    "    df_info = pd.read_csv(info_path, sep='\\t', usecols=[0, 1, 4])\n",
    "    df_peak_data = pd.read_csv(bed_path, sep='\\t', usecols=[0, 1, 2], names=[\"chromosome\", \"peak_start\", \"peak_end\"])\n",
    "\n",
    "    # Get genes and initialize features df with False as entries\n",
    "    df_features = pd.DataFrame(data=0, columns=[i - max_distance - 1 for i in range(1, 2 * (max_distance + 1))],\n",
    "                               index=df_info[\"gene_name\"], dtype=\"int8\")\n",
    "\n",
    "    # Fill df according to info data\n",
    "    for i in df_info.index:\n",
    "        gene = df_info[\"gene_name\"][i]\n",
    "        tss = df_info[\"TSS_start\"][i]\n",
    "        chromosome = df_info[\"chr\"][i]\n",
    "        tss_l = tss - max_distance\n",
    "        tss_r = tss + max_distance\n",
    "\n",
    "        # Print progress\n",
    "        if verbose:\n",
    "            if i == 0:\n",
    "                print(\"Start preprocessing of:\", \"\\n\" +\n",
    "                      \"Dataset:\", bed_path, \"\\n\" +\n",
    "                      \"Infoset:\", info_path)\n",
    "            if i == df_info.index[-1]:\n",
    "                print(\"Done!\" + \"\\n\" + \"-----------------------------------\")\n",
    "\n",
    "        # Find relevant peaks\n",
    "        peaks = df_peak_data.loc[(df_peak_data[\"peak_start\"] < tss_r) &\n",
    "                                 (df_peak_data[\"peak_end\"] > tss_l)]\n",
    "\n",
    "        # Fill features dataset\n",
    "        for j in range(peaks.shape[0]):\n",
    "            # Make sure that peak is on the same chromosome\n",
    "            if peaks[\"chromosome\"].iloc[j] != chromosome: continue\n",
    "\n",
    "            # Get peak boundaries\n",
    "            peak_l = peaks[\"peak_start\"].iloc[j]\n",
    "            peak_r = peaks[\"peak_end\"].iloc[j]\n",
    "\n",
    "            # Consider possible cases\n",
    "            if (peak_l >= tss_l) and (peak_r <= tss_r):\n",
    "                df_features.loc[[gene], peak_l - tss: peak_r - tss] = 1\n",
    "\n",
    "            elif (peak_l <= tss_r) and (peak_r >= tss_r):\n",
    "                df_features.loc[[gene], peak_l - tss: tss_r - tss] = 1\n",
    "\n",
    "            elif (peak_l <= tss_l) and (peak_r <= tss_r):\n",
    "                df_features.loc[[gene], tss_l - tss: peak_r - tss] = 1\n",
    "\n",
    "            elif (peak_l <= tss_l) and (peak_r <= tss_r):\n",
    "                df_features.loc[[gene], tss_l - tss: tss_r - tss] = 1\n",
    "\n",
    "    # Introduce resolution (rather inefficient...)\n",
    "    df_features = df_features.rolling(window=resolution,\n",
    "                                      axis=1,\n",
    "                                      step=stride,\n",
    "                                      min_periods=1).mean()\n",
    "\n",
    "    df_features[df_features > 0.5] = 1\n",
    "    df_features[df_features <= 0.5] = 0\n",
    "\n",
    "    return df_features.astype(\"int8\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "### FUNCTION FOR CREATING TRAINING DATASET\n",
    "def create_set(bed_paths, df_info, max_distance, resolution, stride,verbose=1):\n",
    "    \"\"\"\n",
    "    Create training dataset\n",
    "    :param bed_paths:\n",
    "    :param df_info:\n",
    "    :param max_distance:\n",
    "    :param resolution:\n",
    "    :param stride:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    df_train = pd.concat([extract_features(path,df_info, max_distance, resolution, stride,verbose) for path in bed_paths], axis=1)\n",
    "    df_train.columns = [i for i in range(df_train.columns.size)]\n",
    "\n",
    "    return df_train\n",
    "\n",
    "def create_set_np(bed_paths, df_info, max_distance, resolution, stride,verbose=0):\n",
    "    '''\n",
    "    Equivalent to function above but using numpy arrays to gain efficiency in memory and time\n",
    "    :param bed_paths:\n",
    "    :param df_info:\n",
    "    :param max_distance:\n",
    "    :param resolution:\n",
    "    :param stride:\n",
    "    :param verbose:\n",
    "    :return:\n",
    "    '''\n",
    "    for idx,path in enumerate(bed_paths):\n",
    "        n=len(bed_paths)\n",
    "        if idx==0:\n",
    "            temp=extract_features(path,df_info, max_distance, resolution, stride,verbose)\n",
    "            n_genes, n_timestamps=temp.shape\n",
    "            features=np.zeros((n_genes, n_timestamps*n))\n",
    "        else:\n",
    "            features[:,idx*n_timestamps: (idx+1)*n_timestamps]=extract_features(path,df_info, max_distance, resolution, stride,verbose).to_numpy()\n",
    "    return features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def score_func(y, y_pred):\n",
    "    return spearmanr(y,y_pred).statistic\n",
    "\n",
    "scorer=make_scorer(score_func) #needed to be able to use spearmanr as score function in scikit-learn\n",
    "\n",
    "def Train_Test_loop(window_size, resolution,stride,inner_params,train_paths,val_paths,test_paths,mod_identifier_path='1to2',verbose=1):\n",
    "    '''\n",
    "\n",
    "    :param window_size:\n",
    "    :param resolution:\n",
    "    :param stride:\n",
    "    :param inner_params:\n",
    "    :param train_paths: look above to see how to define\n",
    "    :param val_paths:\n",
    "    :param test_paths:\n",
    "    :param verbose:\n",
    "    :return:\n",
    "    '''\n",
    "    results = {}\n",
    "    results['score_test'], results['score_val'], results['time'], results['model'] = [], [], [], []\n",
    "    for a in inner_params.keys():\n",
    "        results[a] = []\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    file_name = path_cwd+'/Models'\n",
    "    counter, n_iter = 0, len(window_size)*len(resolution) #to monitor training progress\n",
    "    outer_params=[window_size, resolution,stride]\n",
    "    outer_params=[[i] if type(i)!= type([]) else i for i in outer_params]\n",
    "    for w in outer_params[0]:\n",
    "        for r in outer_params[1]:\n",
    "            for s in outer_params[2]:\n",
    "                counter += 1\n",
    "                print(f'Iteration {counter} out of {n_iter}\\nWINDOW: {w}, RESOLUTION: {r}, STRIDE:{s}')\n",
    "                start =time.time()\n",
    "                #creation of datasets\n",
    "                y_train = pd.read_csv(train_paths[2], delimiter=\"\\t\")['gex'].to_numpy()\n",
    "                X_train = create_set_np(train_paths[0], train_paths[1], w, r, s)\n",
    "                y_val = pd.read_csv(val_paths[2], delimiter=\"\\t\")['gex'].to_numpy()\n",
    "                X_val = create_set_np(val_paths[0], val_paths[1], w, r, s)\n",
    "                y_test = pd.read_csv(test_paths[2], delimiter=\"\\t\")['gex'].to_numpy()\n",
    "                X_test = create_set_np(test_paths[0], test_paths[1], w, r, s)\n",
    "                X_complete_train = np.concatenate([X_train,X_val])\n",
    "                y_complete_train = np.concatenate([y_train,y_val])\n",
    "                n_train = X_train.shape[0]\n",
    "                CV = [([i for i in range(n_train)],[i for i in range(n_train, y_complete_train.shape[0])])]\n",
    "                end = time.time()\n",
    "                if verbose:\n",
    "                    print(f'Number of features: {X_complete_train.shape[1]}')\n",
    "                    print(f'\\nPre-processing ended in: {round(end-start)} seconds')\n",
    "                #model definition and training\n",
    "                model = xgb.XGBRegressor(booster='gbtree')\n",
    "                opt = BayesSearchCV(\n",
    "                    model,\n",
    "                    inner_params,\n",
    "                    scoring = scorer,\n",
    "                    n_iter = 40,\n",
    "                    random_state = 7,\n",
    "                    cv = CV,\n",
    "                    verbose = 0)\n",
    "                start = time.time()\n",
    "                opt.fit(X_complete_train,y_complete_train)\n",
    "                end = time.time()\n",
    "                #results update\n",
    "                score = spearmanr(opt.predict(X_test),y_test).statistic\n",
    "                if verbose:\n",
    "                    print(f'Hyperparameter search ended in: {round(end-start)} seconds\\n'\n",
    "                          f'Optimal hyper parameters:{[(a,b) for a,b in opt.best_params_.items()]}\\n'\n",
    "                          f'Score in Validation: {round(opt.best_score_,4)}')\n",
    "                    print(f'Score in Test Set: {round(score,4)}\\n------------------')\n",
    "                results['score_test']+=[round(score,4)]\n",
    "                results['score_val']+=[round(opt.best_score_,4)]\n",
    "                results['time']+=[round(end-start)]\n",
    "                for a,b in opt.best_params_.items():\n",
    "                    results[a]+=[b]\n",
    "                results['model']=opt.best_estimator_\n",
    "                if score> best_score:\n",
    "                    best_model_index = (w,r,s)\n",
    "                    best_score = score\n",
    "                    pickle.dump(opt,open(path_cwd+'/Models/best_model'+ mod_identifier_path+'.pickle','wb'))\n",
    "    index = pd.MultiIndex.from_product(outer_params,names=['window_size','resolution','stride'])\n",
    "    results = pd.DataFrame(results, index=index)\n",
    "    pickle.dump(results, open(path_cwd + '/Models/results' + mod_identifier_path+ '.pickle', 'wb'))\n",
    "    return results, best_model_index\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "window_size=[100,200]\n",
    "resolution=[10,20]\n",
    "stride=10\n",
    "\n",
    "\n",
    "inner_params={\n",
    "    'n_estimators': Integer(20,150),\n",
    "    'learning_rate': Real(1e-5,1e-1,prior='log-uniform'),\n",
    "    'max_depth': Integer(1,10),\n",
    "    'reg_lambda':Integer(1,100)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 out of 4\n",
      "WINDOW: 100, RESOLUTION: 10, STRIDE:10\n",
      "Number of features: 147\n",
      "\n",
      "Pre-processing ended in: 65 seconds\n",
      "Hyperparameter search ended in: 65 seconds\n",
      "Optimal hyper parameters:[('learning_rate', 1e-05), ('max_depth', 6), ('n_estimators', 147), ('reg_lambda', 1)]\n",
      "Score in Validation: 0.7684\n",
      "Score in Test Set: 0.6785\n",
      "------------------\n",
      "Iteration 2 out of 4\n",
      "WINDOW: 100, RESOLUTION: 20, STRIDE:10\n",
      "Number of features: 147\n",
      "\n",
      "Pre-processing ended in: 66 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gugli\\anaconda3\\envs\\pytorch\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter search ended in: 61 seconds\n",
      "Optimal hyper parameters:[('learning_rate', 1e-05), ('max_depth', 5), ('n_estimators', 150), ('reg_lambda', 38)]\n",
      "Score in Validation: 0.7713\n",
      "Score in Test Set: 0.6766\n",
      "------------------\n",
      "Iteration 3 out of 4\n",
      "WINDOW: 200, RESOLUTION: 10, STRIDE:10\n",
      "Number of features: 287\n",
      "\n",
      "Pre-processing ended in: 74 seconds\n",
      "Hyperparameter search ended in: 86 seconds\n",
      "Optimal hyper parameters:[('learning_rate', 0.1), ('max_depth', 4), ('n_estimators', 20), ('reg_lambda', 100)]\n",
      "Score in Validation: 0.7746\n",
      "Score in Test Set: 0.6791\n",
      "------------------\n",
      "Iteration 4 out of 4\n",
      "WINDOW: 200, RESOLUTION: 20, STRIDE:10\n",
      "Number of features: 287\n",
      "\n",
      "Pre-processing ended in: 72 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gugli\\anaconda3\\envs\\pytorch\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\gugli\\anaconda3\\envs\\pytorch\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter search ended in: 82 seconds\n",
      "Optimal hyper parameters:[('learning_rate', 1e-05), ('max_depth', 5), ('n_estimators', 20), ('reg_lambda', 100)]\n",
      "Score in Validation: 0.7748\n",
      "Score in Test Set: 0.6761\n",
      "------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                               score_test  score_val  time  \\\nwindow_size resolution stride                                \n100         10         10          0.6785     0.7684    65   \n            20         10          0.6766     0.7713    61   \n200         10         10          0.6791     0.7746    86   \n            20         10          0.6761     0.7748    82   \n\n                                                                           model  \\\nwindow_size resolution stride                                                      \n100         10         10      XGBRegressor(base_score=None, booster='gbtree'...   \n            20         10      XGBRegressor(base_score=None, booster='gbtree'...   \n200         10         10      XGBRegressor(base_score=None, booster='gbtree'...   \n            20         10      XGBRegressor(base_score=None, booster='gbtree'...   \n\n                               n_estimators  learning_rate  max_depth  \\\nwindow_size resolution stride                                           \n100         10         10               147        0.00001          6   \n            20         10               150        0.00001          5   \n200         10         10                20        0.10000          4   \n            20         10                20        0.00001          5   \n\n                               reg_lambda  \nwindow_size resolution stride              \n100         10         10               1  \n            20         10              38  \n200         10         10             100  \n            20         10             100  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>time</th>\n      <th>model</th>\n      <th>n_estimators</th>\n      <th>learning_rate</th>\n      <th>max_depth</th>\n      <th>reg_lambda</th>\n    </tr>\n    <tr>\n      <th>window_size</th>\n      <th>resolution</th>\n      <th>stride</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">100</th>\n      <th>10</th>\n      <th>10</th>\n      <td>0.6785</td>\n      <td>0.7684</td>\n      <td>65</td>\n      <td>XGBRegressor(base_score=None, booster='gbtree'...</td>\n      <td>147</td>\n      <td>0.00001</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <th>10</th>\n      <td>0.6766</td>\n      <td>0.7713</td>\n      <td>61</td>\n      <td>XGBRegressor(base_score=None, booster='gbtree'...</td>\n      <td>150</td>\n      <td>0.00001</td>\n      <td>5</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">200</th>\n      <th>10</th>\n      <th>10</th>\n      <td>0.6791</td>\n      <td>0.7746</td>\n      <td>86</td>\n      <td>XGBRegressor(base_score=None, booster='gbtree'...</td>\n      <td>20</td>\n      <td>0.10000</td>\n      <td>4</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <th>10</th>\n      <td>0.6761</td>\n      <td>0.7748</td>\n      <td>82</td>\n      <td>XGBRegressor(base_score=None, booster='gbtree'...</td>\n      <td>20</td>\n      <td>0.00001</td>\n      <td>5</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths=[bed_file_paths_X1,train_info_X1_path, train_y_X1_path]\n",
    "val_paths=[bed_file_paths_X1,val_info_X1_path, val_y_X1_path]\n",
    "test_paths=[bed_file_paths_X2,val_info_X2_path, val_y_X2_path]\n",
    "results,best_model=Train_Test_loop(window_size, resolution,stride,inner_params,train_paths,val_paths,test_paths,mod_identifier_path='1to2',verbose=1)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 out of 4\n",
      "WINDOW: 100, RESOLUTION: 10, STRIDE:10\n",
      "Number of features: 147\n",
      "\n",
      "Pre-processing ended in: 66 seconds\n",
      "Hyperparameter search ended in: 66 seconds\n",
      "Optimal hyper parameters:[('learning_rate', 1e-05), ('max_depth', 6), ('n_estimators', 147), ('reg_lambda', 1)]\n",
      "Score in Validation: 0.7684\n",
      "Score in Test Set: 0.6785\n",
      "------------------\n",
      "Iteration 2 out of 4\n",
      "WINDOW: 100, RESOLUTION: 20, STRIDE:10\n",
      "Number of features: 147\n",
      "\n",
      "Pre-processing ended in: 76 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gugli\\anaconda3\\envs\\pytorch\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter search ended in: 60 seconds\n",
      "Optimal hyper parameters:[('learning_rate', 1e-05), ('max_depth', 5), ('n_estimators', 150), ('reg_lambda', 38)]\n",
      "Score in Validation: 0.7713\n",
      "Score in Test Set: 0.6766\n",
      "------------------\n",
      "Iteration 3 out of 4\n",
      "WINDOW: 200, RESOLUTION: 10, STRIDE:10\n",
      "Number of features: 287\n",
      "\n",
      "Pre-processing ended in: 69 seconds\n",
      "Hyperparameter search ended in: 77 seconds\n",
      "Optimal hyper parameters:[('learning_rate', 0.1), ('max_depth', 4), ('n_estimators', 20), ('reg_lambda', 100)]\n",
      "Score in Validation: 0.7746\n",
      "Score in Test Set: 0.6791\n",
      "------------------\n",
      "Iteration 4 out of 4\n",
      "WINDOW: 200, RESOLUTION: 20, STRIDE:10\n",
      "Number of features: 287\n",
      "\n",
      "Pre-processing ended in: 66 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gugli\\anaconda3\\envs\\pytorch\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\gugli\\anaconda3\\envs\\pytorch\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter search ended in: 77 seconds\n",
      "Optimal hyper parameters:[('learning_rate', 1e-05), ('max_depth', 5), ('n_estimators', 20), ('reg_lambda', 100)]\n",
      "Score in Validation: 0.7748\n",
      "Score in Test Set: 0.6761\n",
      "------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                               score_test  score_val  time  \\\nwindow_size resolution stride                                \n100         10         10          0.6785     0.7684    66   \n            20         10          0.6766     0.7713    60   \n200         10         10          0.6791     0.7746    77   \n            20         10          0.6761     0.7748    77   \n\n                                                                           model  \\\nwindow_size resolution stride                                                      \n100         10         10      XGBRegressor(base_score=None, booster='gbtree'...   \n            20         10      XGBRegressor(base_score=None, booster='gbtree'...   \n200         10         10      XGBRegressor(base_score=None, booster='gbtree'...   \n            20         10      XGBRegressor(base_score=None, booster='gbtree'...   \n\n                               n_estimators  learning_rate  max_depth  \\\nwindow_size resolution stride                                           \n100         10         10               147        0.00001          6   \n            20         10               150        0.00001          5   \n200         10         10                20        0.10000          4   \n            20         10                20        0.00001          5   \n\n                               reg_lambda  \nwindow_size resolution stride              \n100         10         10               1  \n            20         10              38  \n200         10         10             100  \n            20         10             100  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>time</th>\n      <th>model</th>\n      <th>n_estimators</th>\n      <th>learning_rate</th>\n      <th>max_depth</th>\n      <th>reg_lambda</th>\n    </tr>\n    <tr>\n      <th>window_size</th>\n      <th>resolution</th>\n      <th>stride</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">100</th>\n      <th>10</th>\n      <th>10</th>\n      <td>0.6785</td>\n      <td>0.7684</td>\n      <td>66</td>\n      <td>XGBRegressor(base_score=None, booster='gbtree'...</td>\n      <td>147</td>\n      <td>0.00001</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <th>10</th>\n      <td>0.6766</td>\n      <td>0.7713</td>\n      <td>60</td>\n      <td>XGBRegressor(base_score=None, booster='gbtree'...</td>\n      <td>150</td>\n      <td>0.00001</td>\n      <td>5</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">200</th>\n      <th>10</th>\n      <th>10</th>\n      <td>0.6791</td>\n      <td>0.7746</td>\n      <td>77</td>\n      <td>XGBRegressor(base_score=None, booster='gbtree'...</td>\n      <td>20</td>\n      <td>0.10000</td>\n      <td>4</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <th>10</th>\n      <td>0.6761</td>\n      <td>0.7748</td>\n      <td>77</td>\n      <td>XGBRegressor(base_score=None, booster='gbtree'...</td>\n      <td>20</td>\n      <td>0.00001</td>\n      <td>5</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths=[bed_file_paths_X1,train_info_X1_path, train_y_X1_path]\n",
    "val_paths=[bed_file_paths_X1,val_info_X1_path, val_y_X1_path]\n",
    "test_paths=[bed_file_paths_X2,val_info_X2_path, val_y_X2_path]\n",
    "\n",
    "\n",
    "results,best_model=Train_Test_loop(window_size, resolution,stride,inner_params,train_paths,val_paths,test_paths,mod_identifier_path='2to1',verbose=1)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "BayesSearchCV(cv=[([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n                    17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, ...],\n                   [14310, 14311, 14312, 14313, 14314, 14315, 14316, 14317,\n                    14318, 14319, 14320, 14321, 14322, 14323, 14324, 14325,\n                    14326, 14327, 14328, 14329, 14330, 14331, 14332, 14333,\n                    14334, 14335, 14336, 14337, 14338, 14339, ...])],\n              estimator=XGBRegressor(base_score=None, booster='gbtree',\n                                     c...\n              n_iter=40, random_state=7, scoring=make_scorer(score_func),\n              search_spaces={'learning_rate': Real(low=1e-05, high=0.1, prior='log-uniform', transform='normalize'),\n                             'max_depth': Integer(low=1, high=10, prior='uniform', transform='normalize'),\n                             'n_estimators': Integer(low=20, high=150, prior='uniform', transform='normalize'),\n                             'reg_lambda': Integer(low=1, high=100, prior='uniform', transform='normalize')})",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=[([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n                    17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, ...],\n                   [14310, 14311, 14312, 14313, 14314, 14315, 14316, 14317,\n                    14318, 14319, 14320, 14321, 14322, 14323, 14324, 14325,\n                    14326, 14327, 14328, 14329, 14330, 14331, 14332, 14333,\n                    14334, 14335, 14336, 14337, 14338, 14339, ...])],\n              estimator=XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;,\n                                     c...\n              n_iter=40, random_state=7, scoring=make_scorer(score_func),\n              search_spaces={&#x27;learning_rate&#x27;: Real(low=1e-05, high=0.1, prior=&#x27;log-uniform&#x27;, transform=&#x27;normalize&#x27;),\n                             &#x27;max_depth&#x27;: Integer(low=1, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n                             &#x27;n_estimators&#x27;: Integer(low=20, high=150, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n                             &#x27;reg_lambda&#x27;: Integer(low=1, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=[([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n                    17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, ...],\n                   [14310, 14311, 14312, 14313, 14314, 14315, 14316, 14317,\n                    14318, 14319, 14320, 14321, 14322, 14323, 14324, 14325,\n                    14326, 14327, 14328, 14329, 14330, 14331, 14332, 14333,\n                    14334, 14335, 14336, 14337, 14338, 14339, ...])],\n              estimator=XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;,\n                                     c...\n              n_iter=40, random_state=7, scoring=make_scorer(score_func),\n              search_spaces={&#x27;learning_rate&#x27;: Real(low=1e-05, high=0.1, prior=&#x27;log-uniform&#x27;, transform=&#x27;normalize&#x27;),\n                             &#x27;max_depth&#x27;: Integer(low=1, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n                             &#x27;n_estimators&#x27;: Integer(low=20, high=150, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n                             &#x27;reg_lambda&#x27;: Integer(low=1, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To load the model\n",
    "mod=pickle.load(open(path_cwd+'/Models/best_model1to2.pickle','rb'))\n",
    "mod"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                               score_test  score_val  time  \\\nwindow_size resolution stride                                \n100         10         10          0.6785     0.7684    65   \n            20         10          0.6766     0.7713    61   \n200         10         10          0.6791     0.7746    86   \n            20         10          0.6761     0.7748    82   \n\n                                                                           model  \\\nwindow_size resolution stride                                                      \n100         10         10      XGBRegressor(base_score=None, booster='gbtree'...   \n            20         10      XGBRegressor(base_score=None, booster='gbtree'...   \n200         10         10      XGBRegressor(base_score=None, booster='gbtree'...   \n            20         10      XGBRegressor(base_score=None, booster='gbtree'...   \n\n                               n_estimators  learning_rate  max_depth  \\\nwindow_size resolution stride                                           \n100         10         10               147        0.00001          6   \n            20         10               150        0.00001          5   \n200         10         10                20        0.10000          4   \n            20         10                20        0.00001          5   \n\n                               reg_lambda  \nwindow_size resolution stride              \n100         10         10               1  \n            20         10              38  \n200         10         10             100  \n            20         10             100  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>time</th>\n      <th>model</th>\n      <th>n_estimators</th>\n      <th>learning_rate</th>\n      <th>max_depth</th>\n      <th>reg_lambda</th>\n    </tr>\n    <tr>\n      <th>window_size</th>\n      <th>resolution</th>\n      <th>stride</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">100</th>\n      <th>10</th>\n      <th>10</th>\n      <td>0.6785</td>\n      <td>0.7684</td>\n      <td>65</td>\n      <td>XGBRegressor(base_score=None, booster='gbtree'...</td>\n      <td>147</td>\n      <td>0.00001</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <th>10</th>\n      <td>0.6766</td>\n      <td>0.7713</td>\n      <td>61</td>\n      <td>XGBRegressor(base_score=None, booster='gbtree'...</td>\n      <td>150</td>\n      <td>0.00001</td>\n      <td>5</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">200</th>\n      <th>10</th>\n      <th>10</th>\n      <td>0.6791</td>\n      <td>0.7746</td>\n      <td>86</td>\n      <td>XGBRegressor(base_score=None, booster='gbtree'...</td>\n      <td>20</td>\n      <td>0.10000</td>\n      <td>4</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <th>10</th>\n      <td>0.6761</td>\n      <td>0.7748</td>\n      <td>82</td>\n      <td>XGBRegressor(base_score=None, booster='gbtree'...</td>\n      <td>20</td>\n      <td>0.00001</td>\n      <td>5</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=pickle.load(open(path_cwd+'/Models/results1to2.pickle','rb'))\n",
    "res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
