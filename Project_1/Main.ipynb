{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import spearmanr\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.metrics import make_scorer\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "np.int = np.int64\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bed and bigwig files contain signals of all chromosomes (including sex chromosomes).\n",
    "# Training and validation split based on chromosomes has been done for you.\n",
    "# However, you can resplit the data in any way you want.\n",
    "\n",
    "# Path for datasets\n",
    "path_cwd = os.getcwd()\n",
    "path_data = path_cwd+\"/ML4G_Project_1_Data\"\n",
    "\n",
    "# Metadata for genes of cell lines X1 and X2\n",
    "train_info_X1_path = path_data+\"/CAGE-train/CAGE-train/X1_train_info.tsv\"\n",
    "train_info_X2_path = path_data+\"/CAGE-train/CAGE-train/X2_train_info.tsv\"\n",
    "val_info_X1_path = path_data+\"/CAGE-train/CAGE-train/X1_val_info.tsv\"\n",
    "val_info_X2_path = path_data+\"/CAGE-train/CAGE-train/X2_val_info.tsv\"\n",
    "\n",
    "test_info_X3_path = path_data+\"/CAGE-train/CAGE-train/X3_test_info.tsv\"\n",
    "\n",
    "# Gene expression values for cell lines X1 and X2\n",
    "train_y_X1_path = path_data+\"/CAGE-train/CAGE-train/X1_train_y.tsv\"\n",
    "train_y_X2_path = path_data+\"/CAGE-train/CAGE-train/X2_train_y.tsv\"\n",
    "val_y_X1_path = path_data+\"/CAGE-train/CAGE-train/X1_val_y.tsv\"\n",
    "val_y_X2_path = path_data+\"/CAGE-train/CAGE-train/X2_val_y.tsv\"\n",
    "\n",
    "# DNase and histone modification data for cell lines X1, X2 and X3\n",
    "bed_files_X1 = [\"/DNase-bed/X1.bed\",\n",
    "                \"/H3K4me1-bed/X1.bed\",\n",
    "                \"/H3K4me3-bed/X1.bed\",\n",
    "                \"/H3K9me3-bed/X1.bed\",\n",
    "                \"/H3K27ac-bed/X1.bed\",\n",
    "                \"/H3K27me3-bed/X1.bed\",\n",
    "                \"/H3K36me3-bed/X1.bed\"]\n",
    "bed_file_paths_X1 = [path_data+file for file in bed_files_X1]\n",
    "\n",
    "bed_files_X2 = [\"/DNase-bed/X2.bed\",\n",
    "                \"/H3K4me1-bed/X2.bed\",\n",
    "                \"/H3K4me3-bed/X2.bed\",\n",
    "                \"/H3K9me3-bed/X2.bed\",\n",
    "                \"/H3K27ac-bed/X2.bed\",\n",
    "                \"/H3K27me3-bed/X2.bed\",\n",
    "                \"/H3K36me3-bed/X2.bed\"]\n",
    "bed_file_paths_X2 = [path_data+file for file in bed_files_X1]\n",
    "\n",
    "bed_files_X3 = [\"/DNase-bed/X3.bed\",\n",
    "                \"/H3K4me1-bed/X3.bed\",\n",
    "                \"/H3K4me3-bed/X3.bed\",\n",
    "                \"/H3K9me3-bed/X3.bed\",\n",
    "                \"/H3K27ac-bed/X3.bed\",\n",
    "                \"/H3K27me3-bed/X3.bed\",\n",
    "                \"/H3K36me3-bed/X3.bed\"]\n",
    "bed_file_paths_X3 = [path_data+file for file in bed_files_X1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTION FOR EXTRACTION OF FEATURES\n",
    "def extract_features(bed_path, info_path, max_distance, resolution, stride, verbose=0, use_score=True):\n",
    "    \"\"\"\n",
    "    Function extracting binary features from bed datasets\n",
    "    :param bed_path: path to bed file of interest\n",
    "    :param info_path: path to info file of interest\n",
    "    :param max_distance: maximal distance from TSS that should be considered\n",
    "    :param resolution: window size of aggregation for dimensionality reduction\n",
    "    :param stride: stride for dimensionality reduction\n",
    "    :return: pandas df of type int8 containing binary features\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data\n",
    "    df_info = pd.read_csv(info_path, sep='\\t', usecols=[0,1,4])\n",
    "\n",
    "    # Get peak data with score column\n",
    "    if (\"DNase\" in bed_path):\n",
    "        score_col = 6\n",
    "    else: score_col = 4\n",
    "\n",
    "    df_peak_data = pd.read_csv(bed_path, sep='\\t', usecols=[0,1,2,score_col], names = [\"chromosome\", \"peak_start\", \"peak_end\", \"score\"])\n",
    "    # Get genes and initialize features df with False as entries\n",
    "    if use_score: df_features = pd.DataFrame(data=0,columns=[i-max_distance-1 for i in range(1, 2*(max_distance+1))], index=df_info[\"gene_name\"], dtype=float)\n",
    "    else: df_features = pd.DataFrame(data=0,columns=[i-max_distance-1 for i in range(1, 2*(max_distance+1))], index=df_info[\"gene_name\"])\n",
    "\n",
    "    # Fill df according to info data\n",
    "    for i in df_info.index:\n",
    "        gene = df_info[\"gene_name\"][i]\n",
    "        tss = df_info[\"TSS_start\"][i]\n",
    "        chromosome = df_info[\"chr\"][i]\n",
    "        tss_l = tss - max_distance\n",
    "        tss_r = tss + max_distance\n",
    "\n",
    "        # Print progress\n",
    "        if verbose:\n",
    "            if i == 0:\n",
    "                print(\"Start preprocessing of:\", \"\\n\"+\n",
    "                      \"Dataset:\", bed_path, \"\\n\"+\n",
    "                      \"Infoset:\", info_path)\n",
    "            if i == df_info.index[-1]:\n",
    "                print(\"Done!\" + \"\\n\" + \"-----------------------------------\")\n",
    "\n",
    "        # Find relevant peaks\n",
    "        peaks = df_peak_data.loc[(df_peak_data[\"peak_start\"] <= tss_r) &\n",
    "                                 (df_peak_data[\"peak_end\"] >= tss_l)]\n",
    "\n",
    "        # Fill features dataset\n",
    "        for j in range(peaks.shape[0]):\n",
    "            # Make sure that peak is on the same chromosome\n",
    "            if peaks[\"chromosome\"].iloc[j] != chromosome: continue\n",
    "\n",
    "            # Get peak boundaries\n",
    "            peak_l = peaks[\"peak_start\"].iloc[j]\n",
    "            peak_r = peaks[\"peak_end\"].iloc[j]\n",
    "\n",
    "            if use_score:\n",
    "                # Get score\n",
    "                score = peaks[\"score\"].iloc[j]\n",
    "            else:\n",
    "                score = 1\n",
    "\n",
    "            # Consider possible cases\n",
    "            if (peak_l >= tss_l) and (peak_r <= tss_r):\n",
    "                df_features.loc[[gene], peak_l-tss : peak_r-tss] = score\n",
    "\n",
    "            elif (peak_l <= tss_r) and (peak_r >= tss_r):\n",
    "                df_features.loc[[gene], peak_l-tss : tss_r-tss] = score\n",
    "\n",
    "            elif (peak_l <= tss_l) and (peak_r <= tss_r):\n",
    "                df_features.loc[[gene], tss_l-tss : peak_r-tss] = score\n",
    "\n",
    "            elif (peak_l <= tss_l) and (peak_r >= tss_r):\n",
    "                df_features.loc[[gene], tss_l-tss : tss_r-tss] = score\n",
    "\n",
    "    # Introduce resolution (rather inefficient...)\n",
    "    df_features=df_features.rolling(window=resolution,\n",
    "                                    step=stride,\n",
    "                                    axis=1,\n",
    "                                    min_periods=1,\n",
    "                                    center=True).mean()\n",
    "\n",
    "    return df_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTION FOR CREATING TRAINING DATASET\n",
    "\n",
    "def create_set_np(bed_paths, df_info, max_distance, resolution, stride,verbose=0, use_score=True):\n",
    "    '''\n",
    "    create training validation and test dataset\n",
    "    :param bed_paths:\n",
    "    :param df_info:\n",
    "    :param max_distance:\n",
    "    :param resolution:\n",
    "    :param stride:\n",
    "    :param verbose:\n",
    "    :return:\n",
    "    '''\n",
    "    for idx,path in enumerate(bed_paths):\n",
    "        n=len(bed_paths)\n",
    "        if idx==0:\n",
    "            temp=extract_features(path,df_info, max_distance, resolution, stride, verbose, use_score)\n",
    "            n_genes, n_timestamps=temp.shape\n",
    "            features=np.zeros((n_genes, n_timestamps*n))\n",
    "            features[:,:n_timestamps]=temp\n",
    "        else:\n",
    "            features[:,idx*n_timestamps: (idx+1)*n_timestamps]=extract_features(path,df_info, max_distance, resolution, stride,verbose).to_numpy()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATION OF SCORE FUNCTION\n",
    "def score_func(y, y_pred):\n",
    "    return spearmanr(y,y_pred).statistic\n",
    "\n",
    "scorer=make_scorer(score_func) #needed to be able to use spearmanr as score function in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATION OF COMPLETE (HPO + TESTING) TRAINING AND TESTING LOOP\n",
    "def Train_Test_loop(outer_params,model,inner_params,train_paths,val_paths,test_paths,mod_identifier_path='1to2',verbose=1):\n",
    "    '''\n",
    "    :param window_size:\n",
    "    :param resolution:\n",
    "    :param stride:\n",
    "    :param model:\n",
    "    :param inner_params: Dictionary describing the search space for the HPO\n",
    "    :param train_paths: look above to see how to define this and the next two parameters\n",
    "    :param val_paths:\n",
    "    :param test_paths:\n",
    "    :param verbose: regulate the printing\n",
    "    :return: a pandas dataframe summarising the result for every combination of the outer parameters and the index for the best model in that dataframe\n",
    "    '''\n",
    "    results = {}\n",
    "    results['score_test'], results['score_val'], results['time'], results['model'],results['n_features'] = [], [], [], [], []\n",
    "    for a in inner_params.keys():\n",
    "        results[a] = []\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    file_name = path_cwd+'/Models'\n",
    "    counter, n_iter = 0, len(outer_params)\n",
    "    for w, r ,s in outer_params:\n",
    "        counter += 1\n",
    "        print(f'Iteration {counter} out of {n_iter}\\nWINDOW: {w}, RESOLUTION: {r}, STRIDE:{s}')\n",
    "        start =time.time()\n",
    "        #creation of datasets\n",
    "        y_train = pd.read_csv(train_paths[2], delimiter=\"\\t\")['gex'].to_numpy()\n",
    "        X_train = create_set_np(train_paths[0], train_paths[1], w, r, s)\n",
    "        y_val = pd.read_csv(val_paths[2], delimiter=\"\\t\")['gex'].to_numpy()\n",
    "        X_val = create_set_np(val_paths[0], val_paths[1], w, r, s)\n",
    "        y_test = pd.read_csv(test_paths[2], delimiter=\"\\t\")['gex'].to_numpy()\n",
    "        X_test = create_set_np(test_paths[0], test_paths[1], w, r, s)\n",
    "        X_complete_train = np.concatenate([X_train,X_val])\n",
    "        y_complete_train = np.concatenate([y_train,y_val])\n",
    "        n_train = X_train.shape[0]\n",
    "        CV = [([i for i in range(n_train)],[i for i in range(n_train, y_complete_train.shape[0])])]\n",
    "        end = time.time()\n",
    "        if verbose:\n",
    "            print(f'Number of features: {X_complete_train.shape[1]}')\n",
    "            print(f'\\nPre-processing ended in: {round(end-start)} seconds')\n",
    "        #model definition and training\n",
    "        results['n_features'] += [X_complete_train.shape[1]]\n",
    "        model = model\n",
    "        opt = BayesSearchCV(\n",
    "            model,\n",
    "            inner_params,\n",
    "            scoring = scorer,\n",
    "            n_iter = 30,\n",
    "            random_state = 7,\n",
    "            cv = CV,\n",
    "            verbose = 0)\n",
    "        start = time.time()\n",
    "        opt.fit(X_complete_train,y_complete_train)\n",
    "        end = time.time()\n",
    "        #results update\n",
    "        score = spearmanr(opt.predict(X_test),y_test).statistic\n",
    "        if verbose:\n",
    "            print(f'Hyperparameter search ended in: {round(end-start)} seconds\\n'\n",
    "                    f'Optimal hyper parameters:{[(a,b) for a,b in opt.best_params_.items()]}\\n'\n",
    "                    f'Score in Validation: {round(opt.best_score_,4)}')\n",
    "            print(f'Score in Test Set: {round(score,4)}\\n------------------')\n",
    "        results['score_test']+=[round(score,4)]\n",
    "        results['score_val']+=[round(opt.best_score_,4)]\n",
    "        results['time']+=[round(end-start)]\n",
    "        for a,b in opt.best_params_.items():\n",
    "            results[a]+=[b]\n",
    "        results['model']=opt.best_estimator_\n",
    "        if score> best_score:\n",
    "            best_model_index = (w,r,s)\n",
    "            best_score = score\n",
    "            pickle.dump(opt,open(path_cwd+'/Results/best_model'+ mod_identifier_path+'.pickle','wb'))\n",
    "        pickle.dump(results,open(path_cwd+'/Results/intermediate'+ mod_identifier_path+'.pickle','wb'))\n",
    "    index = pd.MultiIndex.from_tuples(outer_params, names=['window_size','resolution','stride'])\n",
    "    results = pd.DataFrame(results, index=index)\n",
    "    pickle.dump(results, open(path_cwd + '/Results/DF' + mod_identifier_path+ '.pickle', 'wb'))\n",
    "    return results, best_model_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING OF PARAMETERS FOR THE LOOP FUNCTION\n",
    "\n",
    "outer_params= [(100,10,1), (500,20,10), (1000,30,20), (2000,45,35), (3000,50,45)]\n",
    "\n",
    "train_paths=[bed_file_paths_X1,train_info_X1_path, train_y_X1_path]\n",
    "val_paths=[bed_file_paths_X1,val_info_X1_path, val_y_X1_path]\n",
    "test_paths=[bed_file_paths_X2,val_info_X2_path, val_y_X2_path]\n",
    "\n",
    "\n",
    "model=xgb.XGBRegressor(booster='gbtree')\n",
    "\n",
    "inner_params={\n",
    "    'n_estimators': Integer(100,300),\n",
    "    'learning_rate': Real(1e-5, 3e-1,prior='log-uniform'),\n",
    "    'max_depth': Integer(1,10),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 out of 5\n",
      "WINDOW: 100, RESOLUTION: 10, STRIDE:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1407\n",
      "\n",
      "Pre-processing ended in: 65 seconds\n",
      "Hyperparameter search ended in: 772 seconds\n",
      "Optimal hyper parameters:[('learning_rate', 0.023960977249880475), ('max_depth', 8), ('n_estimators', 100)]\n",
      "Score in Validation: 0.7945\n",
      "Score in Test Set: 0.6982\n",
      "------------------\n",
      "Iteration 2 out of 5\n",
      "WINDOW: 500, RESOLUTION: 20, STRIDE:10\n",
      "Number of features: 707\n",
      "\n",
      "Pre-processing ended in: 75 seconds\n",
      "Hyperparameter search ended in: 324 seconds\n",
      "Optimal hyper parameters:[('learning_rate', 0.006771133137623331), ('max_depth', 8), ('n_estimators', 300)]\n",
      "Score in Validation: 0.8024\n",
      "Score in Test Set: 0.7029\n",
      "------------------\n",
      "Iteration 3 out of 5\n",
      "WINDOW: 1000, RESOLUTION: 30, STRIDE:20\n",
      "Number of features: 707\n",
      "\n",
      "Pre-processing ended in: 72 seconds\n",
      "Hyperparameter search ended in: 285 seconds\n",
      "Optimal hyper parameters:[('learning_rate', 0.010623311897245238), ('max_depth', 6), ('n_estimators', 166)]\n",
      "Score in Validation: 0.795\n",
      "Score in Test Set: 0.6979\n",
      "------------------\n",
      "Iteration 4 out of 5\n",
      "WINDOW: 2000, RESOLUTION: 45, STRIDE:35\n",
      "Number of features: 805\n",
      "\n",
      "Pre-processing ended in: 89 seconds\n",
      "Hyperparameter search ended in: 325 seconds\n",
      "Optimal hyper parameters:[('learning_rate', 0.004312973312584184), ('max_depth', 7), ('n_estimators', 300)]\n",
      "Score in Validation: 0.7952\n",
      "Score in Test Set: 0.6879\n",
      "------------------\n",
      "Iteration 5 out of 5\n",
      "WINDOW: 3000, RESOLUTION: 50, STRIDE:45\n",
      "Number of features: 938\n",
      "\n",
      "Pre-processing ended in: 96 seconds\n",
      "Hyperparameter search ended in: 409 seconds\n",
      "Optimal hyper parameters:[('learning_rate', 0.005973966861800206), ('max_depth', 10), ('n_estimators', 300)]\n",
      "Score in Validation: 0.7929\n",
      "Score in Test Set: 0.7071\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "results,best_model_index=Train_Test_loop(outer_params,\n",
    "                                         model,\n",
    "                                         inner_params,\n",
    "                                         train_paths,\n",
    "                                         val_paths,\n",
    "                                         test_paths,\n",
    "                                         mod_identifier_path='1to2',\n",
    "                                         verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML4G",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
